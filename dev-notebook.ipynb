{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "agricultural-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import time\n",
    "import utils\n",
    "import glob\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim.lr_scheduler as lr\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import torchmetrics as tm\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import Trainer, seed_everything\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-beauty",
   "metadata": {},
   "source": [
    "### Fixing seed for Reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "outside-application",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 121\n",
    "seed_everything(seed, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-scotland",
   "metadata": {},
   "source": [
    "### Config setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "important-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./cil_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "electric-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "learning_rate = 0.005\n",
    "\n",
    "data_workers = 8\n",
    "\n",
    "train_eval_ratio = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-chamber",
   "metadata": {},
   "source": [
    "### Data Transformations and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wrapped-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cil_data import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "behavioral-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, data_dir: str = data_dir, batch_size: int = batch_size):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.data_transform = transforms.Compose([\n",
    "            data.ToTensor()\n",
    "        ])\n",
    "  \n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        \n",
    "        #TODO: how to create data loaders? Is the data set correctly created?\n",
    "        \n",
    "        self.dataset_train_val = data.RoadSegmentationDataset(\n",
    "            os.path.join(self.data_dir, \"training/training/images/\"),\n",
    "            transform=self.data_transform\n",
    "        )\n",
    "        \n",
    "        self.dataset_train_val_truth = data.RoadSegmentationDataset(\n",
    "            os.path.join(self.data_dir, \"training/training/groundtruth/\"), \n",
    "            transform=self.data_transform\n",
    "        )\n",
    "        \n",
    "        self.dataset_test = data.RoadSegmentationDataset(\n",
    "            os.path.join(self.data_dir, \"test_images/test_images/\"), \n",
    "            transform=self.data_transform\n",
    "        )\n",
    "        \n",
    "        dataset_size = len(self.dataset_train_val)\n",
    "        train_split_size = int(dataset_size * train_eval_ratio)\n",
    "        \n",
    "        # how do we split the images and truth images together?\n",
    "        self.dataset_train, self.dataset_val = random_split(self.dataset_train_val, \n",
    "                                                            [train_split_size, dataset_size - train_split_size])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.dataset_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.dataset_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "worthy-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_module = DataModule(data_dir)\n",
    "d_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-forty",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "optimum-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_loss',\n",
    "   patience=15,\n",
    "   verbose=2,\n",
    "   mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "blind-arabic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Running in fast_dev_run mode: will run a full train, val and test loop using 1 batch(es).\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    deterministic=True,\n",
    "    fast_dev_run=True,\n",
    "    #gpus=-1, \n",
    "    #auto_select_gpus=True, \n",
    "    #auto_lr_find=True, \n",
    "    #benchmark=True,    \n",
    "    progress_bar_refresh_rate=10,\n",
    "    stochastic_weight_avg=True, \n",
    "    auto_scale_batch_size='binsearch',\n",
    "    callbacks=[early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "minute-occupation",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'system' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7cb8904414db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'system' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.tune(system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(system)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ikernel_cil",
   "language": "python",
   "name": "ikernel_cil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
