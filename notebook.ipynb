{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIL Project 3 - Road Segmentaion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import time\n",
    "import utils\n",
    "import glob\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim.lr_scheduler as lr\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import torchmetrics as tm\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import Trainer, seed_everything\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing seed for Reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 121\n",
    "seed_everything(seed, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move out of repo and then into the cil data folder\n",
    "data_dir = \"../cil_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "bs_train = batch_size\n",
    "bs_eval = batch_size\n",
    "\n",
    "learning_rate = 0.005\n",
    "\n",
    "data_workers = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformations and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):   \n",
    "    def __init__(self, data_dir: str = './'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        self.train_transform = transforms.Compose(\n",
    "            [\n",
    "                \n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.valid_transform = transforms.Compose(\n",
    "            [\n",
    "                \n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.test_transform = transforms.Compose(\n",
    "            [\n",
    "                \n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):  \n",
    "        if stage in (None, 'fit'):\n",
    "            self.train_data = Dataset(os.path.join(self.data_dir, \"training\"), transform=self.train_transform)\n",
    "            self.valid_data = Dataset(os.path.join(self.data_dir, \"validation\"), transform=self.valid_transform)\n",
    "\n",
    "        if stage in (None, 'test'):\n",
    "            self.test_data = Dataset(os.path.join(self.data_dir, \"test\"), transform=self.test_transform, is_test=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_data,\n",
    "            batch_size=bs_train,\n",
    "            shuffle=True,\n",
    "            num_workers=data_workers,\n",
    "            drop_last=True,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valid_data,\n",
    "            batch_size=bs_eval,\n",
    "            shuffle=False,\n",
    "            num_workers=data_workers,\n",
    "            drop_last=True,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_data,\n",
    "            batch_size=bs_eval,\n",
    "            shuffle=False,\n",
    "            num_workers=data_workers,\n",
    "            pin_memory=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7016e28e21ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_run\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-adc60726c8bb>\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "data = DataModule(data_dir)\n",
    "data.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and System Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningSimpleSystem(pl.LightningModule):\n",
    "    def __init__(self, model, datamodule: pl.LightningDataModule=None, batch_size=batch_size, lr=learning_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        self.datamodule = datamodule\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        \n",
    "        #self.me = MetricsEngine(C.METRIC_TARGET_LENGTHS)\n",
    "        #self.me.reset()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        \n",
    "        y_pred = self.model(X)\n",
    "       \n",
    "        loss = tm.functional.mean_squared_error(y_pred, y)\n",
    "        \n",
    "        self.log('mse', loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        \n",
    "        y_pred = self.model(X)\n",
    "       \n",
    "        loss = self.calculate_metric(y_pred, y)\n",
    "        \n",
    "        self.log('val_loss', loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, seq_ids = batch\n",
    "        \n",
    "        y_pred = self.model(X)\n",
    "        \n",
    "        return dict(list(zip(seq_ids, list(zip(y_pred.detach().cpu().numpy(), X.detach().cpu().numpy())))))\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        results = {k: v for d in outputs for k, v in d.items()}\n",
    "        \n",
    "        self.test_results = results\n",
    "    \n",
    "    def calculate_metric(self, y_pred, y):\n",
    "        self.me.reset()\n",
    "        self.me.compute_and_aggregate(y_pred, y)\n",
    "        \n",
    "        return system.me.get_final_metrics()['joint_angle'].mean() * 24\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.datamodule.train_dataloader()\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.datamodule.val_dataloader()\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.datamodule.test_dataloader()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = lr.ReduceLROnPlateau(optimizer, patience=4, verbose=2)\n",
    "        \n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': scheduler,\n",
    "            'monitor': 'val_loss'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, feature_size_in=135, feature_size_out=540, bias=True, n_nodes=135):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        \n",
    "        self.feature_size_in = feature_size_in\n",
    "        self.feature_size_out = feature_size_out\n",
    "        \n",
    "        self.weights = nn.Parameter(torch.FloatTensor(feature_size_in, feature_size_out))\n",
    "        self.attention = nn.Parameter(torch.FloatTensor(n_nodes, n_nodes))\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(feature_size_out))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weights.size(1))\n",
    "        self.weights.data.uniform_(-stdv, stdv)\n",
    "        self.attention.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    \n",
    "    def forward(self, input):\n",
    "        support = torch.matmul(input, self.weights)\n",
    "        output = torch.matmul(self.attention, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_features, hidden_features, p_dropout, n_nodes=135):\n",
    "        super(GCN, self).__init__()\n",
    "        \n",
    "        self.gc1 = GraphConvolution(input_features, hidden_features, n_nodes=n_nodes)\n",
    "        self.bn1 = nn.BatchNorm1d(n_nodes * hidden_features)\n",
    "        \n",
    "        self.gc2 = GraphConvolution(hidden_features, hidden_features, n_nodes=n_nodes)\n",
    "        self.bn2 = nn.BatchNorm1d(n_nodes * hidden_features)\n",
    "        \n",
    "        self.gc3 = GraphConvolution(hidden_features, input_features, n_nodes=n_nodes)\n",
    "\n",
    "        self.do = nn.Dropout(p_dropout)\n",
    "        self.ac = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.gc1(x)\n",
    "        b, n, f = y.shape\n",
    "        y = self.bn1(y.view(b, -1)).view(b, n, f)\n",
    "        y = self.ac(y)\n",
    "        y = self.do(y)\n",
    "        \n",
    "        y = self.gc2(y)\n",
    "        b, n, f = y.shape\n",
    "        y = self.bn2(y.view(b, -1)).view(b, n, f)\n",
    "        y = self.ac(y)\n",
    "        y = self.do(y)\n",
    "\n",
    "        y = self.gc3(y)\n",
    "        y = y + x\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cupcake/.local/lib/python3.9/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model_name = \"SequentialModel\"\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,drop):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size,\n",
    "                          hidden_size,\n",
    "                          1,\n",
    "                          #bidirectional = True,\n",
    "                          batch_first=True, dropout=drop\n",
    "                         )\n",
    "        self.fc = nn.Linear(hidden_size,hidden_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        dct_m, idct_m = get_dct_matrix(3)\n",
    "        dct_m = torch.from_numpy(dct_m).float().cuda()\n",
    "        idct_m = torch.from_numpy(idct_m).float().cuda()\n",
    "        \n",
    "        src_value_tmp = X.reshape(-1,3,3)\n",
    "        src_value_tmp = torch.matmul(dct_m[:8].unsqueeze(dim=0),src_value_tmp).reshape(X.shape)\n",
    "        #out, hidden = self.rnn(X)\n",
    "        out, hidden = self.rnn(src_value_tmp)\n",
    "        hidden = hidden.transpose(0,1)\n",
    "        hidden = self.fc(hidden)\n",
    "        hidden = hidden.transpose(0,1)\n",
    "\n",
    "        return out, hidden\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,drop):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size,\n",
    "                          hidden_size,\n",
    "                          1,\n",
    "                          batch_first=True, dropout=drop\n",
    "                         )\n",
    "        self.fc_out = nn.Linear(hidden_size,hidden_size)\n",
    "        \n",
    "    def forward(self, X, hidden_in):\n",
    "        \n",
    "        out, hidden_out = self.rnn(X, hidden_in)\n",
    "        output = torch.zeros_like(out).cuda()\n",
    "        output[:,-1,:] = self.fc_out(out[:,-1,:])\n",
    "                \n",
    "        return output, hidden_out\n",
    "    \n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(enc_hid_dim + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        enc_hid_dim = hidden.shape[2]\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        \n",
    "        before_hidden = hidden\n",
    "        out_hidden = torch.zeros(src_len, batch_size, enc_hid_dim).cuda()\n",
    "        \"\"\"\n",
    "        for i in range(src_len):\n",
    "            out_hidden[i,:,:] = hidden[0,:,:]\n",
    "        \"\"\"\n",
    "        out_hidden[:,:,:] = hidden[0,:,:]\n",
    "\n",
    "        before_hidden = torch.cat((before_hidden,before_hidden),dim=0)\n",
    "\n",
    "        \n",
    "        out_hidden = out_hidden.transpose(0,1)\n",
    "        \n",
    "        to_att = torch.cat((out_hidden, encoder_outputs), dim = 2)\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((out_hidden, encoder_outputs), dim = 2))) \n",
    "        \n",
    "\n",
    "        a = self.v(energy).squeeze(2)\n",
    "        \n",
    "        \n",
    "        return F.softmax(a, dim=1)    \n",
    "\n",
    "\n",
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,drop,attention):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size+hidden_size,\n",
    "                          hidden_size,\n",
    "                          1,\n",
    "                          batch_first=True, dropout=drop\n",
    "                         )\n",
    "        self.fc_out = nn.Linear(hidden_size*3,input_size)\n",
    "        \n",
    "    def forward(self, X, hidden_in,encoder_outputs):\n",
    "        \n",
    "        a = self.attention(hidden_in,encoder_outputs)\n",
    "        \n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        weighted = torch.bmm(a,encoder_outputs)\n",
    "        \n",
    "        rnn_input = torch.cat((X,weighted),dim=2)\n",
    "        \n",
    "        out, hidden_out = self.rnn(rnn_input, hidden_in)\n",
    "\n",
    "        \n",
    "        X = X.squeeze(0)\n",
    "        out = out.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        output = torch.zeros_like(out).cuda()\n",
    "\n",
    "\n",
    "        to_fc2 = torch.cat((out,weighted,X),dim=2)\n",
    "\n",
    "        to_input = to_fc2.squeeze(1)\n",
    "\n",
    "       \n",
    "        output[:,-1,:] = self.fc_out(to_input)\n",
    "                              \n",
    "        return output, hidden_out\n",
    "      \n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder,output_seq_length):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        self.gcn = GCN(input_features=144*2, hidden_features=512, p_dropout=0.3, n_nodes=135)\n",
    "        \n",
    "        self.output_seq_length = output_seq_length\n",
    "        \n",
    "        \n",
    "    def forward(self,X):\n",
    "        \n",
    "        #print(X.shape)\n",
    "\n",
    "        outputs = torch.zeros_like(X[:,:self.output_seq_length,:])\n",
    "        \n",
    "        encoder_out, hidden = self.encoder(X)\n",
    "        \n",
    "        #print(\"encoder_out shape: \", encoder_out.shape)\n",
    "        #print(\"encoder out hidden shape: \", hidden.shape)\n",
    "        \n",
    "        input = X[:,-1,:].unsqueeze(1)\n",
    "        \n",
    "        for i in range(24):\n",
    "            \n",
    "            output, hidden_out = self.decoder(input, hidden ,encoder_outputs=encoder_out)\n",
    "            \n",
    "            outputs[:,i,:] = output[:,-1,:]\n",
    "            \n",
    "            input = output\n",
    "            hidden = hidden_out\n",
    "    \n",
    "        dct_m, idct_m = get_dct_matrix(3)\n",
    "        dct_m = torch.from_numpy(dct_m).float().cuda()\n",
    "        idct_m = torch.from_numpy(idct_m).float().cuda()\n",
    "        \n",
    "        dct_gcn, idct_gcn = get_dct_matrix(144)\n",
    "        dct_gcn = torch.from_numpy(dct_gcn).float().cuda()\n",
    "        idct_gcn = torch.from_numpy(idct_gcn).float().cuda()\n",
    "        \n",
    "        out_33 = outputs.reshape(-1,3,3)\n",
    "        back_out = torch.matmul(idct_m[:8].unsqueeze(dim=0), out_33).reshape(outputs.shape)\n",
    "        \n",
    "        #print(\"X: \", X.shape)\n",
    "        #print(\"back_outs: \", back_out.shape)\n",
    "        last_el = X[:, -1, :]\n",
    "        #print(\"last eel: \", last_el.shape)\n",
    "        padded = torch.cat((X, last_el.unsqueeze(1).repeat(1, 24, 1)), 1)\n",
    "        #print(\"padded:\", padded.shape)\n",
    "        \n",
    "        concat_out = torch.cat((X, back_out), 1)\n",
    "        #print(\"concat_out: \", concat_out.shape)\n",
    "        \n",
    "        \n",
    "        # to dct\n",
    "        \n",
    "        padded_dct = torch.matmul(dct_gcn[:].unsqueeze(dim=0), padded).transpose(1,2)\n",
    "        \n",
    "        out_dct = torch.matmul(dct_gcn[:].unsqueeze(dim=0), concat_out).transpose(1,2)\n",
    "        gcn_in = torch.cat([padded_dct, out_dct], dim=-1)\n",
    "        \n",
    "        gcn_output = self.gcn(gcn_in)\n",
    "        output_restored = torch.matmul(idct_gcn[:, :144].unsqueeze(dim=0), gcn_output[:, :, :144].transpose(1,2))\n",
    "        #print(\"restored outp:\", output_restored.shape)\n",
    "    \n",
    "      \n",
    "        return output_restored[:, -24:, :]\n",
    "\n",
    "\n",
    "    \n",
    "encoder = Encoder(input_size=135,hidden_size=135,drop=0.2)\n",
    "attention_model = Attention(enc_hid_dim=135,dec_hid_dim=135)\n",
    "decoder = AttentionDecoder(input_size=135,hidden_size=135,drop=0.2,attention=attention_model)\n",
    "model = Seq2Seq(encoder,decoder,output_seq_length=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = LightningSimpleSystem(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataModule' object has no attribute 'train_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-323c9c1aea74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-6dc92e8b9d06>\u001b[0m in \u001b[0;36mtrain_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-adc60726c8bb>\u001b[0m in \u001b[0;36mtrain_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         return DataLoader(\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataModule' object has no attribute 'train_data'"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(system.train_dataloader()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup saving environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we make it nicer than just having the time as the name?\n",
    "Somehow increase the experiment id everytime we save it?\n",
    "Perhaps when running a test:  \n",
    "   - See in directory which experiment id was last\n",
    "   - Increast that id by 1\n",
    "   - Save model parameters, prediction in the corresponding folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = int(time.time())\n",
    "experiment_name = model_name\n",
    "model_dir = utils.create_model_dir(C.EXPERIMENT_DIR, experiment_id, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_files = glob.glob('./*.py', recursive=False)\n",
    "utils.export_code(code_files, os.path.join(model_dir, 'code.zip'))\n",
    "config.to_json(os.path.join(model_dir, 'config.json'))  ## parameters form configuration.py\n",
    "# The parameters can change since we use pytorch lightning\n",
    "\n",
    "cmd = sys.argv[0] + ' ' + ' '.join(sys.argv[1:])\n",
    "with open(os.path.join(model_dir, 'cmd.txt'), 'w') as f:\n",
    "    f.write(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_loss',\n",
    "   patience=15,\n",
    "   verbose=2,\n",
    "   mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    deterministic=True,\n",
    "    #fast_dev_run=True,\n",
    "    gpus=-1, \n",
    "    auto_select_gpus=True, \n",
    "    #auto_lr_find=True, \n",
    "    #lr=0.00001,\n",
    "    #benchmark=True,    \n",
    "    progress_bar_refresh_rate=10,\n",
    "    stochastic_weight_avg=True, \n",
    "    auto_scale_batch_size='binsearch',\n",
    "    #limit_train_batches=32, #batch size is 16\n",
    "    callbacks=[early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 666\n",
      "Batch size 2 succeeded, trying batch size 4\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 666\n",
      "Batch size 4 succeeded, trying batch size 8\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 666\n",
      "Batch size 8 succeeded, trying batch size 16\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 666\n",
      "Batch size 16 succeeded, trying batch size 32\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 666\n",
      "Batch size 32 succeeded, trying batch size 64\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 666\n",
      "Batch size 64 succeeded, trying batch size 128\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 666\n",
      "Batch size 128 succeeded, trying batch size 256\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 666\n",
      "Batch size 256 succeeded, trying batch size 512\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 666\n",
      "Batch size 512 succeeded, trying batch size 1024\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 666\n",
      "Batch size 1024 succeeded, trying batch size 2048\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 666\n",
      "Batch size 2048 succeeded, trying batch size 4096\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 666\n",
      "Batch size 4096 succeeded, trying batch size 8192\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 666\n",
      "Batch size 4170 succeeded, trying batch size 8340\n",
      "Finished batch size finder, will continue with full run using batch size 4170\n",
      "Restored states from the checkpoint file at /cluster/home/vvisuval/project4/scale_batch_size_temp_model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'scale_batch_size': 4170}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.tune(system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | Seq2Seq | 1.3 M \n",
      "----------------------------------\n",
      "1.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 M     Total params\n",
      "5.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73644de1dda94f3497ea94deaf9fd7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d85062d0a84c4daf60e4a870bbac1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 2it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 4.070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.197 >= min_delta = 0.0. New best score: 3.872\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     8: reducing learning rate of group 0 to 1.5849e-04.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.616 >= min_delta = 0.0. New best score: 3.257\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.127 >= min_delta = 0.0. New best score: 3.129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.168 >= min_delta = 0.0. New best score: 2.961\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    19: reducing learning rate of group 0 to 1.5849e-05.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.037 >= min_delta = 0.0. New best score: 2.924\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.018 >= min_delta = 0.0. New best score: 2.906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    28: reducing learning rate of group 0 to 1.5849e-06.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.021 >= min_delta = 0.0. New best score: 2.885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 2.870\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    36: reducing learning rate of group 0 to 1.5849e-07.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    41: reducing learning rate of group 0 to 1.5849e-08.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 15 records. Best score: 2.870. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    46: reducing learning rate of group 0 to 1.5849e-09.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(model_dir, 'saved_model_state.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and save in right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c23fc8093f437fa9d797708283fa5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = system.test_results\n",
    "len(results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'predictions_in{}_out{}.csv'.format(config.seed_seq_len, config.target_seq_len)\n",
    "evaluate._export_results(results, os.path.join(model_dir, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/home/vvisuval/experiments/1624177738-SequentialModel\n"
     ]
    }
   ],
   "source": [
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_mp",
   "language": "python",
   "name": "env_mp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
