{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.io import ImageReadMode\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "from torchvision.transforms.functional import convert_image_dtype\n",
    "\n",
    "import pl_bolts\n",
    "from pl_bolts.models.vision import UNet\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "import torchmetrics as tm\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadSatelliteModule(pl.LightningDataModule):\n",
    "    def prepare_data(self):\n",
    "        self.train_images = self.read_images('train/images/', ImageReadMode.RGB)\n",
    "        self.train_masks = self.read_images('train/groundtruth/', ImageReadMode.GRAY)\n",
    "    \n",
    "        for i, train_mask in enumerate(self.train_masks):\n",
    "            self.train_masks[i][self.train_masks[i] > 0] = 1\n",
    "            \n",
    "        self.train_zip = list(zip(self.train_images, self.train_masks))\n",
    "        \n",
    "        self.test_images = self.read_images('test/', ImageReadMode.RGB)\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        if stage in (None, 'fit'):\n",
    "            train_length = int(len(self.train_zip) * 0.8)\n",
    "            valid_length = len(self.train_zip) - train_length\n",
    "\n",
    "            self.train_data, self.valid_data = random_split(self.train_zip, [train_length, valid_length])\n",
    "            \n",
    "        if stage in (None, 'test'):\n",
    "            self.test_data = self.test_images\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=16)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valid_data, batch_size=16)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=16)\n",
    "    \n",
    "    def read_images(self, data_dir, read_mode):\n",
    "        return [read_image(data_dir + file, read_mode) for file in os.listdir(data_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_data = RoadSatelliteModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_data.prepare_data()\n",
    "road_data.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_images = [draw_segmentation_masks(train_pair[0], train_pair[1].bool()) for train_pair in road_data.train_zip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for seg_image in seg_images:\n",
    "#    show_image(seg_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSegmentationSystem(pl.LightningModule):\n",
    "    def __init__(self, model: nn.Module, datamodule: pl.LightningDataModule, lr: float = 1e-4, batch_size: int = 16):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = model\n",
    "        self.datamodule = datamodule\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        \n",
    "        X = X.float()\n",
    "        y = y.float()\n",
    "        \n",
    "        y_pred = self.model(X)\n",
    "       \n",
    "        loss = sigmoid_focal_loss(y_pred, y, reduction='mean')\n",
    "        \n",
    "        self.log('training_loss', loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "                \n",
    "        X = X.float()\n",
    "        y = y.int()\n",
    "        \n",
    "        y_pred = self.model(X)\n",
    "        y_sig = torch.sigmoid(y_pred)\n",
    "       \n",
    "        metric = tm.functional.accuracy(y_sig, y, average='samples')\n",
    "        \n",
    "        self.log('validation_metric', metric)\n",
    "        \n",
    "        return metric\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, _ = batch\n",
    "        \n",
    "        return self.model(X)\n",
    "    \n",
    "    def visualize_results(self):\n",
    "        Xs, ys = next(iter(self.val_dataloader()))\n",
    "                \n",
    "        y_preds = torch.sigmoid(self.model(X.float()))\n",
    "        \n",
    "        for y_pred in y_preds:\n",
    "            show_image(y_pred)\n",
    "            \n",
    "    def visualize_results_overlay(self):\n",
    "        Xs, ys = next(iter(self.val_dataloader()))\n",
    "                \n",
    "        y_preds = torch.sigmoid(self.model(Xs.float()))\n",
    "        \n",
    "        pred_zip = list(zip(Xs, y_preds))\n",
    "        \n",
    "        seg_images = [draw_segmentation_masks(train_pair[0], train_pair[1].round().bool(), colors=['#00ff00']) for train_pair in pred_zip]\n",
    "        \n",
    "        for seg_image in seg_images:\n",
    "            show_image(seg_image)\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return self.datamodule.train_dataloader()\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.datamodule.val_dataloader()\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.datamodule.test_dataloader()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=4, verbose=2)\n",
    "        \n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': scheduler,\n",
    "            'monitor': 'validation_metric'\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 1, 5, padding='same'),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(1, 3, 5, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(road_data.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = SemanticSegmentationSystem(model, road_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.visualize_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.visualize_results_overlay()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='validation_metric',\n",
    "   patience=10,\n",
    "   verbose=2,\n",
    "   mode='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    #fast_dev_run=True,\n",
    "    gpus=-1,\n",
    "    auto_select_gpus=True,\n",
    "    auto_lr_find=True,\n",
    "    auto_scale_batch_size='binsearch',\n",
    "    stochastic_weight_avg=True,\n",
    "    deterministic=True,\n",
    "    callbacks=[early_stop_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.tune(system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.visualize_results_overlay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mp-env)",
   "language": "python",
   "name": "mp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
